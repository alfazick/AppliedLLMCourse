{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAMY+wKm2jJzQhnnmLRquh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
},

    
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfazick/AppliedLLMCourse/blob/main/Module1InferenceControl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705,
          "referenced_widgets": [
            "7672e3a2064a4311982ba437a589b54d",
            "ffb54a5ed6f844538c2d9331bea06ab0",
            "f11e1de8ca0d446ca023cb313176c2ee",
            "618e13918f8b41ecb01f007a834152ed",
            "f2e3614c77d44f36b9bcef8b99c9ea19",
            "6138e19d6a974fa497839a72962085f0",
            "c0f9f8e991c24a6d907ed08169d868ce",
            "6171519048b64383a53e79e254e55823",
            "79ccdc99951d484faa98d0bee116cb21",
            "7735f84458634a5fbbe939113eb3f4a0",
            "0461cbf1661e4b35b05f8f7cfba0115b",
            "f180890a644b41e786019fee9f069020",
            "684e3421cc764a95b3f43e487fc11a3b",
            "2c77d752a46f4b7bb51f05aee41856c4",
            "3bf7b7594e804b23ba3e1e7ee921dddb",
            "b5b0334c999c4f59965956fce0e4b068",
            "379be6425d6740ad923a968f1a313b72",
            "410d85549e7d46f0aa093b15693c4bad",
            "660653488d5241649ee7eea7e4a97eac",
            "d1abe6e523f94042a7030254783e8aee",
            "1dda425a0c874447b81f26c5828d1b39",
            "c79e79700b964507ac963f0795207afb",
            "aa987e1c1ecb409a8e501cc0b111e595",
            "7e4b0d2cebd64c28b21f08109c24dfe9",
            "1bba17dd3b59489e97070b7e7fac74b1",
            "23c7a49ab2284dab86e11d3a3697959c",
            "7a0b6fa0da4d4680be4327a41a83bec9",
            "9cf68990650c4e6fbfebbd71cfa78f73",
            "eb510933e242407fad52154eea0118c0",
            "d0e73a4caa0f4feca45ef98ad9e103fd",
            "fcea4a2b64f04ed384ddddb3214c1a19",
            "ab10dee4d7844bcebd26d465efdf6269",
            "df1d482f5afe4b92a79d2794ec1f709d",
            "bc061ec99da748a0b94f29892827660e",
            "51546723d5cd4bdd84801f9d5b4a6148",
            "3b8462c444434f36b613dea6807c1206",
            "b162ba9ec0b947229362389ed27796c6",
            "3a7ca0d4d3614d09ba71882f70a47792",
            "8fb26abd184142b79df06e4012a0dd68",
            "0c2a9e68f53d4739b955882c38ff14e9",
            "5b1c63a86ea34e65bea29ad556e2e2e1",
            "77e61e6bcbb84a60b0fa8c534dee97e9",
            "f57f980a23c74caea5e01aab5757a76c",
            "678070267a9c4fe88e3e942321c4a8bd",
            "c10ddd2e034148ec911ddceb9768514a",
            "6081a858041b4a60b6e7108412e7f8bb",
            "f3eebd7c00e2464a8f24dc5c08a57949",
            "46589e80d59445c8bfa8a18392c9b8e3",
            "6ed4464d9be6445190bdcdfe7da15601",
            "06e044ee93f24f3f84e98021eb2cbe92",
            "b62dd349437941089b27953e671e8ca7",
            "3f8a0d7c46ed4af7a4d3ba8b4bd9c507",
            "d699d2a0ca6c46ffa9667c83f0bf89dc",
            "ed2c138ebb4b4463be6ce6240967ead8",
            "4b1a26f7494d4a51830ce6d7716965a3",
            "2514e0bbe3e04502a673b44cf05509a1",
            "737c2d308238484995f266ee05b3ad43",
            "9fb77acbecc94b64b2e98597cb767d13",
            "cedcb01290e348438879a541fcb3c019",
            "11863baf1a494f3ab11d0cb07efc4101",
            "b2a9fb2a80a94076952620fe62bfe32d",
            "84a47eada05e48868b2d6233fe1f204c",
            "6bd98cdc82bd4a268381a9ee9edf5bcd",
            "cbb513793e844774b76bc4df61f824d5",
            "26062e9c30f5400a8b999e235e2d60e5",
            "c9d04da259de49b58387bef2c97cc6e2",
            "afd2fe29d77a4f2d977d3160ff9d699e",
            "5057c30c6878486cb3b042660055d168",
            "dc015c2652e746a6ad9b0a77188f5950",
            "dd9a7319fae841639d8bc0ccaebd470b",
            "4118de8eb50c451e903a14aa5634a2ff",
            "e66bbaa81a184363b2e37c2ac808438b",
            "5f5995a4e80d4b13abdbff6183b58272",
            "df69ef2c0152452089d7aab5febde080",
            "bd2da2e2d2984d6eb03b5d82fed37040",
            "7a3dde2137654ff68d1c97b5628697b4",
            "65944e9ab924490a893bde7c8894bfdd"
          ]
        },
        "id": "LT44iBpwL39F",
        "outputId": "d1cd5c63-66f0-486d-eb2d-be0bc5f6989c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7672e3a2064a4311982ba437a589b54d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f180890a644b41e786019fee9f069020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa987e1c1ecb409a8e501cc0b111e595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc061ec99da748a0b94f29892827660e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c10ddd2e034148ec911ddceb9768514a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2514e0bbe3e04502a673b44cf05509a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd2fe29d77a4f2d977d3160ff9d699e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "prompt = \"Transformer architecture is \"\n",
        "inputs = tokenizer(prompt,return_tensors = \"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model(**inputs)\n",
        "    raw_logits = out.logits\n",
        "\n",
        "last_row = raw_logits[:,-1,:]\n",
        "\n",
        "# Let us start to formalize different techniques\n",
        "\n",
        "# Greedy\n",
        "\n",
        "def greedy_decode(raw_logits):\n",
        "    probs = F.softmax(raw_logits,dim=-1)\n",
        "    next_token = torch.argmax(probs,dim=-1)\n",
        "    return next_token\n",
        "\n",
        "\n",
        "nxt_token_id = greedy_decode(last_row).item()\n",
        "\n",
        "print(nxt_token_id)\n",
        "print(tokenizer.decode([nxt_token_id]))\n",
        "\n",
        "# ok that's not that useful, but good for recalling the procedure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGSVTJDYMJyL",
        "outputId": "c792c2b2-6938-428e-e618-ce18dd48e4a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ok so we already familiar with this function\n",
        "def generate(model,tokenizer,prompt,max_length=10,fn_decode_strategy=greedy_decode):\n",
        "    inputs = tokenizer(prompt,return_tensors=\"pt\")\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    generated_tokens = list()\n",
        "\n",
        "    for step in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids = input_ids,\n",
        "                        attention_mask = attention_mask)\n",
        "\n",
        "            logits_last = out.logits[:,-1,:]\n",
        "\n",
        "\n",
        "            ### Core plugin idea of decode_strategy\n",
        "\n",
        "            next_token_id = fn_decode_strategy(logits_last)\n",
        "\n",
        "            token_id_int = next_token_id.item()\n",
        "\n",
        "            # next token text\n",
        "            next_token = tokenizer.decode(token_id_int)\n",
        "\n",
        "            if tokenizer.eos_token_id is not None and token_id_int == tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "            generated_tokens.append(next_token)\n",
        "\n",
        "            # now let's update inputs, since we want to continue generations\n",
        "            # with newly minted token in context\n",
        "\n",
        "            # append to context: make shape [1,1], then cat\n",
        "            next_token_2d = next_token_id.view(1, 1)        # [1, 1]\n",
        "\n",
        "            input_ids = torch.cat([input_ids, next_token_2d], dim=1)\n",
        "\n",
        "            attention_mask = torch.cat(\n",
        "                [attention_mask, torch.ones((1, 1), dtype=attention_mask.dtype)], dim=1\n",
        "            )\n",
        "\n",
        "    continuation = \"\".join(generated_tokens)\n",
        "\n",
        "    return continuation, prompt + continuation\n",
        "\n"
      ],
      "metadata": {
        "id": "vkpRyS_QOgC_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's test greedy\n",
        "\n",
        "_,res = generate(model,tokenizer,prompt,10,greedy_decode)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th3mLp0ESLTr",
        "outputId": "9f8cdd4e-f42c-472d-90e9-0f68a733da81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer architecture is 100% open source, and is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so next idea is \"what is a temperature?\"\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_temperature_effects():\n",
        "    # Example logits for 5 tokens\n",
        "    logits = torch.tensor([2.0, 1.5, 0.5, -0.5, -2.0])\n",
        "    temperatures = [0.1, 0.3, 0.5, 1.0,5.0]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "\n",
        "    for idx, temp in enumerate(temperatures):\n",
        "        changed_logits = logits/temp\n",
        "        # so please notice  temperature is applied in way by division\n",
        "        # so basically if value was big it becomes bigger when temp in\n",
        "        # range(0,1)\n",
        "        # and obviosuly you can see after 1, it flattens most of the values\n",
        "        # so like it almost became random\n",
        "\n",
        "\n",
        "        probs = F.softmax(changed_logits,dim=-1)\n",
        "\n",
        "        axes[idx].bar(range(len(probs)), probs.numpy())\n",
        "        axes[idx].set_title(f'T = {temp}')\n",
        "        axes[idx].set_ylim(0, 1)\n",
        "        axes[idx].set_xlabel('Token ID')\n",
        "        axes[idx].set_ylabel('Probability')\n",
        "\n",
        "    plt.suptitle('Effect of Temperature on Probability Distribution')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_temperature_effects()\n",
        "\n",
        "# so this one should be pretty mach illustrative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "E_hfgfZTSXpm",
        "outputId": "4daa35c5-5126-4c7f-988d-dd010e4599c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAErCAYAAAAxE8pmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUAVJREFUeJzt3XlcVXX+x/H3BRVEBXdwxyW3cdc0S0ctCtMWKyutFB2XyV2xJm1KJEs0zag0293S0bJFZzQddy0pU9N0zNJyyxQwExQTBM7vDx/cn1e4woV7uV/h9Xw8eIz3y1k+51zOe+hzD99jsyzLEgAAAAAAAAAAyMbH2wUAAAAAAAAAAGAqmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAMB4Fy5c0ODBgxUSEiKbzaaxY8dKkuLj49W7d29VqlRJNptNsbGxXq3TFc6OCTCZzWbTyJEj3ba9+fPny2azaefOnbku27VrV3Xt2tX++ujRo7LZbJo/f759bPLkybLZbG6rz52yjvXo0aMe39eAAQMUGhpqf511rmbOnOnxfUtmvw8AAAD5QRMdAAB4RVZDydnX119/bV926tSpmj9/voYNG6ZFixapX79+kqRx48Zp7dq1mjhxohYtWqTu3bu7vc6pU6fq888/98h2czqmq2U1onL7urqxWNwcOHBAkydPLpTGpKmuvZb8/f3VsGFDjRw5UvHx8d4uz+s8cQ1v3rzZ4Zz7+fkpODhYXbt21dSpU5WYmOiW/Vy8eFGTJ0/W5s2b3bI9dzK5NgAAAHcr4e0CAABA8fbCCy+obt262cYbNGhg//fGjRt1yy23KCoqymGZjRs36v7779dTTz3lsfqmTp2q3r17q1evXm7drrNjutqDDz7ocB4uXLigYcOG6YEHHtCDDz5oHw8ODnZrbTeSAwcOKDo6Wl27dnW487Y4yrqWLl26pC+//FJz587V6tWrtX//fgUEBHi7vAL773//m+syzz33nCZMmOAw5qlrWJJGjx6tm2++WRkZGUpMTNT27dsVFRWlWbNm6aOPPtLtt99uX7Zfv37q06eP/Pz88rz9ixcvKjo6WpJc+rDs3XffVWZmZp6Xz4/r1ZbT+wAAAHAjo4kOAAC86u6771a7du2uu0xCQoKaNm2a43j58uU9VJlnOTumq7Vo0UItWrSwvz5z5oyGDRumFi1a6IknnvB0iV6RkpKiMmXKeLsMY+pwxdXX0uDBg1WpUiXNmjVLK1asUN++fXNc50Y6zlKlSuW6TIkSJVSiROH9J07nzp3Vu3dvh7G9e/fqrrvu0kMPPaQDBw6oWrVqkiRfX1/5+vp6tJ6s97NkyZIe3U9uCvt9AAAA8DSmcwEAAMbKmjLhyJEjWrVqlX3qhKzpKyzL0pw5c+zjWc6dO6exY8eqVq1a8vPzU4MGDTR9+vRsd2ZmZmbqtddeU/PmzeXv768qVaqoe/fu9vmZbTabUlJStGDBAvs+BgwYcN2aExISNGjQIAUHB8vf318tW7bUggULcj2mgkxHcvDgQfXu3VsVK1aUv7+/2rVrp5UrVzosk3XOvvzyS40ePVpVqlRR+fLl9fe//11paWk6d+6c+vfvrwoVKqhChQr6xz/+Icuy7OtfPafyq6++qjp16qh06dLq0qWL9u/fX6CatmzZouHDh6tq1aqqWbOmJOnYsWMaPny4GjVqpNKlS6tSpUp6+OGHHc7T/Pnz9fDDD0uSunXrZj+XWdNL2Gw2TZ48OVttoaGhDu/j9eqQpC+++EKdO3dWmTJlVK5cOfXs2VP/+9//8vTe/PLLL3r44YdVsWJFBQQE6JZbbtGqVasclsn6mfjoo4/00ksvqWbNmvL399cdd9yhw4cP52k/Ocm6C/rIkSOSrsyTXbZsWf3888/q0aOHypUrp8cff1zSlebr+PHj7ddMo0aNNHPmTIefgastXrxYjRo1kr+/v9q2bautW7c6fD8v79/VLl68qL///e+qVKmSAgMD1b9/f/3xxx8Oy1w7J3pOrp2L29k1vGnTJtlsNn322WfZtrFkyRLZbDbFxcVdd1/OtGzZUrGxsTp37pxmz55tH89pTvSdO3cqPDxclStXVunSpVW3bl397W9/k3TlmqtSpYokKTo62l5/1s/09d7Pa+dEv1pu16+z83z1NnOrLac50dPT0zVlyhTVr19ffn5+Cg0N1bPPPqvU1FSH5UJDQ3XPPffoyy+/VPv27eXv76969epp4cKFOZ9wAACAQsDtAQAAwKuSkpJ05swZhzGbzaZKlSqpSZMmWrRokcaNG6eaNWtq/PjxkqTWrVvb5xG/88471b9/f/u6Fy9eVJcuXXTy5En9/e9/V+3atbV9+3ZNnDhRp06dcnj46KBBgzR//nzdfffdGjx4sNLT07Vt2zZ9/fXXateunRYtWqTBgwerffv2Gjp0qCSpfv36To/lzz//VNeuXXX48GGNHDlSdevW1ccff6wBAwbo3LlzGjNmjNNjympIuep///ufbrvtNtWoUUMTJkxQmTJl9NFHH6lXr1765JNP9MADDzgsP2rUKIWEhCg6Olpff/213nnnHZUvX17bt29X7dq1NXXqVK1evVozZsxQs2bNHM6tJC1cuFDnz5/XiBEjdOnSJb322mu6/fbbtW/fPvu0Mq7WNHz4cFWpUkWTJk1SSkqKJOnbb7/V9u3b1adPH9WsWVNHjx7V3Llz1bVrVx04cEABAQH661//qtGjR+v111/Xs88+qyZNmkiS/X9dlVMdixYtUkREhMLDwzV9+nRdvHhRc+fOVadOnfTdd99ddwqZ+Ph43Xrrrbp48aJGjx6tSpUqacGCBbrvvvu0fPnybOdh2rRp8vHx0VNPPaWkpCS9/PLLevzxx/XNN9/k63h+/vlnSVKlSpXsY+np6QoPD1enTp00c+ZMBQQEyLIs3Xfffdq0aZMGDRqkVq1aae3atXr66ad18uRJvfrqqw7b3bJli5YtW6bRo0fLz89Pb775prp3764dO3aoWbNmkvL2/l1t5MiRKl++vCZPnqwff/xRc+fO1bFjx+wfMOSXs2v4lltuUa1atbR48eJs78PixYtVv359dezYMd/77d27twYNGqT//ve/eumll3JcJiEhQXfddZeqVKmiCRMmqHz58jp69Kg+/fRTSVcyYe7cudmmcLr6r1Nyej+vJy/Xb17kpbZrDR48WAsWLFDv3r01fvx4ffPNN4qJidEPP/yQ7cOMw4cP289hRESEPvjgAw0YMEBt27bVX/7ylzzXCQAA4DYWAACAF8ybN8+SlOOXn5+fw7J16tSxevbsmW0bkqwRI0Y4jE2ZMsUqU6aM9dNPPzmMT5gwwfL19bWOHz9uWZZlbdy40ZJkjR49Ott2MzMz7f8uU6aMFRERkadjio2NtSRZH374oX0sLS3N6tixo1W2bFkrOTk512O6nsTEREuSFRUVZR+74447rObNm1uXLl1yqP/WW2+1brrpJvtY1vkODw93OL6OHTtaNpvNevLJJ+1j6enpVs2aNa0uXbrYx44cOWJJskqXLm39+uuv9vFvvvnGkmSNGzcu3zV16tTJSk9PdzjWixcvZjv+uLg4S5K1cOFC+9jHH39sSbI2bdqUbflrz1WWOnXqOLynzuo4f/68Vb58eWvIkCEO658+fdoKCgrKNn6tsWPHWpKsbdu2OWyzbt26VmhoqJWRkWFZlmVt2rTJkmQ1adLESk1NtS/72muvWZKsffv2XXc/WfWvX7/eSkxMtE6cOGEtXbrUqlSpksP7FRERYUmyJkyY4LD+559/bkmyXnzxRYfx3r17WzabzTp8+LB9LOsa3blzp33s2LFjlr+/v/XAAw/Yx/L6/mXV3rZtWystLc0+/vLLL1uSrBUrVtjHunTpkuPP5Lx58+xjUVFR1rX/iePsGp44caLl5+dnnTt3zj6WkJBglShRIsefm6tlvWcff/yx02VatmxpVahQIduxHjlyxLIsy/rss88sSda3337rdBs5XfNZnL2fWd+rU6eO/bUr1++159nZNq9X27Xvw549eyxJ1uDBgx2We+qppyxJ1saNG+1jderUsSRZW7dutY8lJCRYfn5+1vjx47PtCwAAoDAwnQsAAPCqOXPmaN26dQ5fX3zxRb639/HHH6tz586qUKGCzpw5Y/8KCwtTRkaGfdqJTz75RDabLccHe+b3ztfVq1crJCTEYf7pkiVLavTo0bpw4YK2bNmSv4Ny4uzZs9q4caMeeeQRnT9/3n6sv//+u8LDw3Xo0CGdPHnSYZ1BgwY5HF+HDh1kWZYGDRpkH/P19VW7du30yy+/ZNtnr169VKNGDfvr9u3bq0OHDlq9enW+axoyZEi2uaJLly5t//fly5f1+++/q0GDBipfvrx2796dj7OVu2vrWLdunc6dO6e+ffs6/Cz5+vqqQ4cO2rRp03W3t3r1arVv316dOnWyj5UtW1ZDhw7V0aNHdeDAAYflBw4c6DDvd+fOnSUpx/chJ2FhYapSpYpq1aqlPn36qGzZsvrss88c3i9JGjZsWLY6fX19NXr0aIfx8ePHy7KsbNdjx44d1bZtW/vr2rVr6/7779fatWuVkZEhyfX3b+jQoQ7zeA8bNkwlSpSw/1x5Qv/+/ZWamqrly5fbx5YtW6b09HS3PHOgbNmyOn/+vNPvZz3P4T//+Y8uX76c7/1c+35eT27Xr6dkbT8yMtJhPOsvca6d4qhp06b2n3/pyp3vjRo1yvO1AAAA4G5M5wIAALyqffv2uT5Y1BWHDh3S999/73R6lISEBElXprqoXr26Klas6LZ9Hzt2TDfddJN8fBzvU8iaXuTYsWNu25d0ZcoDy7L0/PPP6/nnn89xmYSEBIemWe3atR2+HxQUJEmqVatWtvFr56SWpJtuuinbWMOGDfXRRx/lu6a6detmW+bPP/9UTEyM5s2bp5MnTzrMzZ2UlJTjdgvq2joOHTok6f/nFr9WYGDgdbd37NgxdejQIdv41T8PWdOfSNnfmwoVKkhSju9DTubMmaOGDRuqRIkSCg4OVqNGjbL9LJYoUcJhvvesOqpXr65y5co5rfNqzn4GLl68qMTERIWEhLj8/l27zbJly6patWoFelZAbho3bqybb75Zixcvtn+ItHjxYt1yyy1q0KBBgbd/4cKFbOf0al26dNFDDz2k6Ohovfrqq+ratat69eqlxx57TH5+fnnaR07v5/Xkdv16yrFjx+Tj45PtvIaEhKh8+fLZfsauvRakK9dDXq8FAAAAd6OJDgAAipTMzEzdeeed+sc//pHj9xs2bFjIFXlO1oNSn3rqKYWHh+e4zLVNq2vv+L7euOXkoZLurunqu5azjBo1SvPmzdPYsWPVsWNHBQUFyWazqU+fPtkeEOuqrLulr3VtHVn7WbRokUJCQrItX6KEe3+Vdvbe5PV9yMsHUn5+ftka657gyffPnfr3768xY8bo119/VWpqqr7++muHh4Hm1+XLl/XTTz85fEhyLZvNpuXLl+vrr7/Wv//9b61du1Z/+9vf9Morr+jrr79W2bJlc92PJ97PrIc2X8vZdePqtvOioNcCAACAu9FEBwAARUr9+vV14cIFhYWF5brc2rVrdfbs2eveje7K1C516tTR999/r8zMTIfG1sGDB+3fd6d69epJujJlTG7H6y5Zd2df7aeffrI/YNNdNS1fvlwRERF65ZVX7GOXLl3SuXPnHJa73vtToUKFbMunpaXp1KlTeaoh6yGyVatWzdex1KlTRz/++GO2cU/9PORXnTp1tH79ep0/f97hzmlndTr7GQgICLD/BUhe37+rt9mtWzf76wsXLujUqVPq0aNHvo8ry/V+Rvr06aPIyEj961//0p9//qmSJUvq0UcfLfA+ly9frj///NPpB0lXu+WWW3TLLbfopZde0pIlS/T4449r6dKlGjx4cIEeqpqT3K5f6cp1k9O0KdfeLe5qNmZmZurQoUMOD/6Nj4/XuXPnjLkWAAAAnGFOdAAAUKQ88sgjiouL09q1a7N979y5c0pPT5ckPfTQQ7IsS9HR0dmWu/puxzJlyjht/F2rR48eOn36tJYtW2YfS09P1xtvvKGyZcuqS5cuLh7N9VWtWlVdu3bV22+/nWNjODEx0a37k6TPP//cYU7zHTt26JtvvtHdd9/t1pp8fX2z3XX6xhtvZLsbtkyZMpKU43tUv359+xz4Wd55550831EbHh6uwMBATZ06Ncc5q3M7lh49emjHjh2Ki4uzj6WkpOidd95RaGiomjZtmqc6PK1Hjx7KyMjIdgf2q6++KpvNZn9vs8TFxTnMa37ixAmtWLFCd911l/0O4ry+f1neeecdh3M8d+5cpaenZ9t3flzvGq5cubLuvvtuffjhh1q8eLG6d++uypUrF2h/e/fu1dixY1WhQgWNGDHC6XJ//PFHtnPUqlUrSVJqaqokKSAgQFLOP9/5kdv1K125bg4ePOjw871371599dVXDttypbasD0NiY2MdxmfNmiVJ6tmzp0vHAQAAUNi4Ex0AAHjVF198Yb/j9Wq33nqr/a5mVzz99NNauXKl7rnnHg0YMEBt27ZVSkqK9u3bp+XLl+vo0aOqXLmyunXrpn79+un111/XoUOH1L17d2VmZmrbtm3q1q2bRo4cKUlq27at1q9fr1mzZql69eqqW7dujvNcS1cejvj2229rwIAB2rVrl0JDQ7V8+XJ99dVXio2Nve78yPk1Z84cderUSc2bN9eQIUNUr149xcfHKy4uTr/++qv27t3r1v01aNBAnTp10rBhw5SamqrY2FhVqlTJYfocd9R0zz33aNGiRQoKClLTpk0VFxen9evXq1KlSg7LtWrVSr6+vpo+fbqSkpLk5+en22+/XVWrVtXgwYP15JNP6qGHHtKdd96pvXv3au3atXlukgYGBmru3Lnq16+f2rRpoz59+qhKlSo6fvy4Vq1apdtuu+26U39MmDBB//rXv3T33Xdr9OjRqlixohYsWKAjR47ok08+KZRpVfLi3nvvVbdu3fTPf/5TR48eVcuWLfXf//5XK1as0NixY+135Gdp1qyZwsPDNXr0aPn5+enNN9+UJIcPpPL6/mVJS0vTHXfcoUceeUQ//vij3nzzTXXq1En33XdfgY8vt2u4f//+6t27tyRpypQpLm1727ZtunTpkjIyMvT777/rq6++0sqVKxUUFKTPPvssx2mAsixYsEBvvvmmHnjgAdWvX1/nz5/Xu+++q8DAQHvTuXTp0mratKmWLVumhg0bqmLFimrWrNl1p4m5nrxcv3/72980a9YshYeHa9CgQUpISNBbb72lv/zlL0pOTrYv50ptLVu2VEREhN555x2dO3dOXbp00Y4dO7RgwQL16tXL4a8QAAAATEQTHQAAeNWkSZNyHJ83b16+mugBAQHasmWLpk6dqo8//lgLFy5UYGCgGjZsqOjoaPuDNLP20aJFC73//vt6+umnFRQUpHbt2unWW2+1LzNr1iwNHTpUzz33nP78809FREQ4baKXLl1amzdv1oQJE7RgwQIlJyerUaNGmjdvngYMGODyseRF06ZNtXPnTkVHR2v+/Pn6/fffVbVqVbVu3drpuS2I/v37y8fHR7GxsUpISFD79u01e/ZsVatWza01vfbaa/L19dXixYt16dIl3XbbbVq/fn226TFCQkL01ltvKSYmRoMGDVJGRoY2bdqkqlWrasiQITpy5Ijef/99rVmzRp07d9a6det0xx135Pl4H3vsMVWvXl3Tpk3TjBkzlJqaqho1aqhz584aOHDgddcNDg7W9u3b9cwzz+iNN97QpUuX1KJFC/373/826s5bHx8frVy5UpMmTdKyZcs0b948hYaGasaMGRo/fny25bt06aKOHTsqOjpax48fV9OmTTV//ny1aNHCvkxe378ss2fP1uLFizVp0iRdvnxZffv21euvv+6W6Uxyu4bvvfdeVahQQZmZmS437V9//XVJV6YvKl++vJo0aaLo6GgNGTLE6cONs2Q1kpcuXar4+HgFBQWpffv2Wrx4scNDbt977z2NGjVK48aNU1pamqKiovLdRM/L9dukSRMtXLhQkyZNUmRkpJo2bapFixZpyZIl2rx5s8P2XKntvffeU7169TR//nz7BwwTJ05UVFRUvo4FAACgMNksns4CAACAXBw9elR169bVjBkz9NRTT3m7HMBt0tPTVb16dd177716//33vV0OAAAADGTG35ACAAAAgBd8/vnnSkxMVP/+/b1dCgAAAAzFdC4AAAAAip1vvvlG33//vaZMmaLWrVu7/cG/AAAAKDq4Ex0AAABAsTN37lwNGzZMVatW1cKFC71dDgAAAAzGnOgAAAAAAAAAADjBnegAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmuhwC5vNlqevzZs3F1pNP/zwg7p3766yZcuqYsWK6tevnxITE/O07rJly/TEE0/opptuks1mU9euXT1bLACPKmoZNW7cOLVp00YVK1ZUQECAmjRposmTJ+vChQserhqAJxS1jAoNDc2x/ieffNLDVQPwBNMyaseOHRo+fLjatm2rkiVLymazubyN7du3q1OnTgoICFBISIhGjx7N71HADcq0jBowYECO+2/cuHGet7Fy5Uq1adNG/v7+ql27tqKiopSenu7BqpEXJbxdAIqGRYsWObxeuHCh1q1bl228SZMmhVLPr7/+qr/+9a8KCgrS1KlTdeHCBc2cOVP79u3Tjh07VKpUqeuuP3fuXO3atUs333yzfv/990KpGYDnFLWM+vbbb9W5c2cNHDhQ/v7++u677zRt2jStX79eW7dulY8Pn5EDN5KillGS1KpVK40fP95hrGHDhp4qGYAHmZZRq1ev1nvvvacWLVqoXr16+umnn1xaf8+ePbrjjjvUpEkTzZo1S7/++qtmzpypQ4cO6YsvvvBQ1QA8xbSMkiQ/Pz+99957DmNBQUF5WveLL75Qr1691LVrV73xxhvat2+fXnzxRSUkJGju3LmeKBd5ZQEeMGLECMubP17Dhg2zSpcubR07dsw+tm7dOkuS9fbbb+e6/vHjx62MjAzLsizrL3/5i9WlSxdPlQrAC270jMrJzJkzLUlWXFycu8oE4CU3ekbVqVPH6tmzpydLBOBF3s6o06dPWxcvXsx3LXfffbdVrVo1KykpyT727rvvWpKstWvXurVWAIXP2xkVERFhlSlTJt/rN23a1GrZsqV1+fJl+9g///lPy2azWT/88IM7SkQ+casaiqRPPvlE99xzj2rXrm0fCwsLU8OGDfXRRx/lun6tWrW4kxOAxxQ0o3ISGhoqSTp37pwbKgRQnLkro9LS0pSSkuKJEgEUY8HBwSpdunS+1k1OTta6dev0xBNPKDAw0D7ev39/lS1bNt+/hwHAtTIyMpScnOzSOgcOHNCBAwc0dOhQlSjx/5OHDB8+XJZlafny5e4uEy5gOhcYIykpSZcvX851OX9/f5UtW9bp90+ePKmEhAS1a9cu2/fat2+v1atXF6hOAMWTaRmVnp6uc+fOKS0tTfv379dzzz2ncuXKqX379nlaH0DRYlpGbdy4UQEBAcrIyFCdOnU0btw4jRkzJk/rAih63JVRBbVv3z6lp6dny7hSpUqpVatW+u677zy2bwDmcndGXbx4UYGBgbp48aIqVKigvn37avr06bmum5VB12ZU9erVVbNmTTLKy2iiwxj333+/tmzZkutyERERmj9/vtPvnzp1SpJUrVq1bN+rVq2azp49q9TUVPn5+eW7VgDFj2kZtXPnTnXs2NH+ulGjRlq5cqUqVqyYa40Aih6TMqpFixbq1KmTGjVqpN9//13z58/X2LFj9dtvv2n69Om5HwyAIsddGVVQuWXctm3bPLZvAOZyZ0ZVq1ZN//jHP9SmTRtlZmZqzZo1evPNN7V3715t3rzZ4Q7za+WWUb/99luuNcJzaKLDGK+88or++OOPXJerXr36db//559/SlKO/3Hn7+9vX4YmOgBXmJZRTZs21bp165SSkqLt27dr/fr1unDhQq71ASiaTMqolStXOrweOHCg7r77bs2aNUujRo1SzZo1c60TQNHirowqqNwyLuv7AIoXd2ZUTEyMw+s+ffqoYcOG+uc//6nly5erT58+TtfNLaNcnR4G7kUTHcZo27atW7aTNT9eampqtu9dunTJYRkAyCvTMiowMFBhYWGSrtw5sWTJEt1///3avXu3WrZs6ZZaAdw4TMuoq9lsNo0bN05r167V5s2b9cQTTxS8UAA3FHdlVEHllnH8dyJQPHk6o8aNG6fnn39e69evv24TnYwyG010GOPs2bNKS0vLdbnSpUsrKCjI6fez/uwl689grnbq1ClVrFiRu9ABuMz0jHrwwQfVr18/LV26lCY6UAyZnlG1atWy1wmg+HFXRhVUbhnn6TvhAZjJ0xlVunRpVapUKdffg67OqKzfnbKcOnWK5195GU10GOPBBx90yxxUNWrUUJUqVbRz585s39uxY4datWpVgCoBFFemZ1RqaqoyMzOVlJSUr/UB3NhMz6hffvlFklSlSpV8rQ/gxuaujCqoZs2aqUSJEtq5c6ceeeQR+3haWpr27NnjMAag+PB0Rp0/f15nzpzJ9fegrN+zdu7c6dAw/+233/Trr79q6NChLu8b7kMTHcZw5xxUDz30kBYsWKATJ07YP73bsGGDfvrpJ40bN86+3OXLl/Xzzz8rKCgoxwc3AEAWUzLq3LlzKlOmjEqWLOmwzffee09S9ie5AygeTMmos2fPKigoSL6+vg7LTZs2TaVKlVK3bt1cPTQARYC35kQ/ePCgAgICVLt2bUlSUFCQwsLC9OGHH+r5559XuXLlJEmLFi3ShQsX9PDDD7t1/wBuDO7KqEuXLuny5cv2bMkyZcoUWZal7t2728dy+j3qL3/5ixo3bqx33nlHf//73+2/T82dO1c2m029e/d29dDgRjTRYQx3zkH17LPP6uOPP1a3bt00ZswYXbhwQTNmzFDz5s01cOBA+3InT55UkyZNsn2auHXrVm3dulWSlJiYqJSUFL344ouSpL/+9a/661//6rZaAdwYTMmozZs3a/To0erdu7duuukmpaWladu2bfr000/Vrl075hoGiilTMmrlypV68cUX1bt3b9WtW1dnz57VkiVLtH//fk2dOlUhISFuqxPAjcOdGXXs2DEtWrRIkux/NZP132p16tRRv3797Ms2adJEXbp00ebNm+1jL730km699VZ16dJFQ4cO1a+//qpXXnlFd911l0ODC0Dx4a6MOn36tFq3bq2+ffuqcePGkqS1a9dq9erV6t69u+6//377ss76UTNmzNB9992nu+66S3369NH+/fs1e/ZsDR48WE2aNHFLncgfmugokmrVqqUtW7YoMjJSEyZMUKlSpdSzZ0+98soreZrHc+PGjYqOjnYYe/755yVJUVFRNNEBFEhBMqp58+bq1q2bVqxYoVOnTsmyLNWvX1+TJk3S008/rVKlShXSUQAoqgqaUU2bNtWHH36oxMRElSpVSq1atdJHH33EHZ4A3OLIkSP2/zbLkvW6S5cuDk30nLRp00br16/XM888o3HjxqlcuXIaNGiQYmJiPFYzgOKhfPnyuueee7Ru3TotWLBAGRkZatCggaZOnaqnnnpKPj4+uW7jnnvu0aeffqro6GiNGjVKVapU0bPPPqtJkyYVwhHgemyWZVneLgIAAAAAAAAAABPl/hEIAAAAAAAAAADFFE10AAAAAAAAAACcoIkOAAAAAAAAAIATXm2ib926Vffee6+qV68um82mzz//PNd1Nm/erDZt2sjPz08NGjRweIItALgTGQXAZGQUAJORUQBMRkYBcJVXm+gpKSlq2bKl5syZk6fljxw5op49e6pbt27as2ePxo4dq8GDB2vt2rUerhRAcURGATAZGQXAZGQUAJORUQBcZbMsy/J2EZJks9n02WefqVevXk6XeeaZZ7Rq1Srt37/fPtanTx+dO3dOa9asKYQqARRXZBQAk5FRAExGRgEwGRkFIC9KeLsAV8TFxSksLMxhLDw8XGPHjnW6TmpqqlJTU+2vMzMzdfbsWVWqVEk2m81TpQJwkWVZOn/+vKpXry4fnxvzcQ1kFFB0kVFXkFGAmcioK8gowExk1BVkFGCmvGbUDdVEP336tIKDgx3GgoODlZycrD///FOlS5fOtk5MTIyio6MLq0QABXTixAnVrFnT22XkCxkFFH1kFACTkVEATEZGATBZbhl1QzXR82PixImKjIy0v05KSlLt2rV14sQJBQYG5rp+syhz5rfaHx3u7RIAj0lOTlatWrVUrlw5b5dSqAqaUQAKBxl1BRkFmImMuoKMAsxERl1BRgFmymtG3VBN9JCQEMXHxzuMxcfHKzAwMMdP/STJz89Pfn5+2cYDAwPzFFo+fgH5K9YDCFkUBzfyn7V5I6MAFC4y6goyCjATGXUFGQWYiYy6gowCzJRbRt1Qk1F17NhRGzZscBhbt26dOnbs6KWKAOD/kVEATEZGATAZGQXAZGQUAK820S9cuKA9e/Zoz549kqQjR45oz549On78uKQrf/rSv39/+/JPPvmkfvnlF/3jH//QwYMH9eabb+qjjz7SuHHjvFE+gCKOjAJgMjIKgMnIKAAmI6MAuMqrTfSdO3eqdevWat26tSQpMjJSrVu31qRJkyRJp06dsgeYJNWtW1erVq3SunXr1LJlS73yyit67733FB7OXOEA3I+MAmAyMgqAycgoACYjowC4ymZZluXtIgpTcnKygoKClJSUlKc5qEInrCqEqvLm6LSe3i4B8BhXr82iivMAmIlr8wrOA2Amrs0rOA+Ambg2r+A8AGbK67V5Q82JDgAAAAAAAABAYaKJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMCJEt4uAACQf6ETVnm7BLuj03p6uwQAAAAAAAC34050AAAAAAAAAACc8HoTfc6cOQoNDZW/v786dOigHTt2XHf52NhYNWrUSKVLl1atWrU0btw4Xbp0qZCqBVDckFEATEZGATAZGQXAZGQUAFd4tYm+bNkyRUZGKioqSrt371bLli0VHh6uhISEHJdfsmSJJkyYoKioKP3www96//33tWzZMj377LOFXDmA4oCMAmAyMgqAycgoACYjowC4yqtN9FmzZmnIkCEaOHCgmjZtqrfeeksBAQH64IMPclx++/btuu222/TYY48pNDRUd911l/r27Zvrp4UAkB9kFACTkVEATEZGATAZGQXAVV5roqelpWnXrl0KCwv7/2J8fBQWFqa4uLgc17n11lu1a9cue0j98ssvWr16tXr06FEoNQMoPsgoACYjowCYjIwCYDIyCkB+lPDWjs+cOaOMjAwFBwc7jAcHB+vgwYM5rvPYY4/pzJkz6tSpkyzLUnp6up588snr/vlMamqqUlNT7a+Tk5PdcwAAijQyCoDJyCgAJiOjAJiMjAKQH15/sKgrNm/erKlTp+rNN9/U7t279emnn2rVqlWaMmWK03ViYmIUFBRk/6pVq1YhVgygOCGjAJiMjAJgMjIKgMnIKABeuxO9cuXK8vX1VXx8vMN4fHy8QkJCclzn+eefV79+/TR48GBJUvPmzZWSkqKhQ4fqn//8p3x8sn8mMHHiREVGRtpfJycnE1wAckVGATAZGQXAZGQUAJORUQDyw2t3opcqVUpt27bVhg0b7GOZmZnasGGDOnbsmOM6Fy9ezBZMvr6+kiTLsnJcx8/PT4GBgQ5fAJAbMgqAycgoACYjowCYjIwCkB9euxNdkiIjIxUREaF27dqpffv2io2NVUpKigYOHChJ6t+/v2rUqKGYmBhJ0r333qtZs2apdevW6tChgw4fPqznn39e9957rz28AMBdyCgAJiOjAJiMjAJgMjIKgKu82kR/9NFHlZiYqEmTJun06dNq1aqV1qxZY3+4w/Hjxx0+6Xvuuedks9n03HPP6eTJk6pSpYruvfdevfTSS946BABFGBkFwGRkFACTkVEATEZGAXCVzXL2dydFVHJysoKCgpSUlJSnP6UJnbCqEKrKm6PTenq7BMBjXL02iyoyCjATGXUF5wEwE9fmFZwHwExcm1dwHgAz5fXa9Nqc6AAAAAAAAAAAmI4mOgAAAAAAAAAATtBEBwAAAAAAAADACZroAAAAAAAAAAA4QRMdAAAAAAAAAAAnaKIDAAAAAAAAAOAETXQAAAAAAAAAAJygiQ4AAAAAAAAAgBM00QEAAAAAAAAAcIImOgAAAAAAAAAATpTwdgEAAAAomkInrPJ2CXZHp/X0dgkAAAAAblD5uhN906ZN7q4DANyGjAJgMjIKgMnIKAAmI6MAeEu+mujdu3dX/fr19eKLL+rEiRPurgkACoSMAmAyMgqAycgoACYjowB4S76a6CdPntTIkSO1fPly1atXT+Hh4froo4+Ulpbm7voAwGVkFACTkVEATEZGATAZGQXAW/LVRK9cubLGjRunPXv26JtvvlHDhg01fPhwVa9eXaNHj9bevXvdXScA5BkZBcBkZBQAk5FRAExGRgHwlnw10a/Wpk0bTZw4USNHjtSFCxf0wQcfqG3bturcubP+97//uaNGAMg3MgqAycgoACYjowCYjIwCUJjy3US/fPmyli9frh49eqhOnTpau3atZs+erfj4eB0+fFh16tTRww8/7M5aASDPyCgAJiOjAJiMjAJgMjIKgDeUyM9Ko0aN0r/+9S9ZlqV+/frp5ZdfVrNmzezfL1OmjGbOnKnq1au7rVAAyCsyCoDJyCgAJiOjAJiMjALgLflqoh84cEBvvPGGHnzwQfn5+eW4TOXKlbVp06YCFQcA+UFGATAZGQXAZGQUAJORUQC8JV/TuURFRenhhx/OFljp6enaunWrJKlEiRLq0qVLwSsEABeRUQBMRkYBMBkZBcBkZBQAb8lXE71bt246e/ZstvGkpCR169atwEUBQEGQUQBMRkYBMBkZBcBkZBQAb8lXE92yLNlstmzjv//+u8qUKVPgogCgIMgoACYjowCYjIwCYDIyCoC3uDQn+oMPPihJstlsGjBggMOfz2RkZOj777/Xrbfe6t4KASCPyCgAJiOjAJiMjAJgMjIKgLe5dCd6UFCQgoKCZFmWypUrZ38dFBSkkJAQDR06VB9++KFLBcyZM0ehoaHy9/dXhw4dtGPHjusuf+7cOY0YMULVqlWTn5+fGjZsqNWrV7u0TwBFExkFwGRkFACTkVEATEZGAfA2l+5EnzdvniQpNDRUTz31VIH/VGbZsmWKjIzUW2+9pQ4dOig2Nlbh4eH68ccfVbVq1WzLp6Wl6c4771TVqlW1fPly1ahRQ8eOHVP58uULVAeAooGMAmAyMgqAycgoACYjowB4m82yLMtbO+/QoYNuvvlmzZ49W5KUmZmpWrVqadSoUZowYUK25d966y3NmDFDBw8eVMmSJfO1z+TkZAUFBSkpKUmBgYG5Lh86YVW+9uMJR6f19HYJgMe4em0WBjLKNWQUijIy6goyCjATGXWFiecBgJnXJhkFIEter80834nepk0bbdiwQRUqVFDr1q1zfJBDlt27d+e6vbS0NO3atUsTJ060j/n4+CgsLExxcXE5rrNy5Up17NhRI0aM0IoVK1SlShU99thjeuaZZ+Tr65vXQwFQBJFRAExGRgEwGRkFwGRkFAAT5LmJfv/999sf3NCrV68C7/jMmTPKyMhQcHCww3hwcLAOHjyY4zq//PKLNm7cqMcff1yrV6/W4cOHNXz4cF2+fFlRUVE5rpOamqrU1FT76+Tk5ALXDsA8ZBQAk5FRAExGRgEwGRkFwAR5bqJfHQrOAsLTMjMzVbVqVb3zzjvy9fVV27ZtdfLkSc2YMcNpTTExMYqOji7kSgEUNjIKgMnIKAAmI6MAmIyMAmACH2/tuHLlyvL19VV8fLzDeHx8vEJCQnJcp1q1amrYsKHDn8o0adJEp0+fVlpaWo7rTJw4UUlJSfavEydOuO8gABRZZBQAk5FRAExGRgEwGRkFID/yfCd6hQoVrjvv1NXOnj2b6zKlSpVS27ZttWHDBvuf42RmZmrDhg0aOXJkjuvcdtttWrJkiTIzM+Xjc6X//9NPP6latWoqVapUjuv4+fnZ/+wHQNFFRgEwGRkFwGRkFACTkVEATJDnJnpsbKzbdx4ZGamIiAi1a9dO7du3V2xsrFJSUjRw4EBJUv/+/VWjRg3FxMRIkoYNG6bZs2drzJgxGjVqlA4dOqSpU6dq9OjRbq8NwI2FjAJgMjIKgMnIKAAmI6MAmCDPTfSIiAi37/zRRx9VYmKiJk2apNOnT6tVq1Zas2aN/eEOx48ft3/CJ0m1atXS2rVrNW7cOLVo0UI1atTQmDFj9Mwzz7i9NgA3FjIKgMnIKAAmI6MAmIyMAmACm2VZVl4WTE5OVmBgoP3f15O1nImSk5MVFBSkpKSkPNUZOmFVIVSVN0en9fR2CYDHuHpt5rQ+GeVdZBSKMjLqCjIKMBMZdUVBzwMAzyCjriCjADPl9dp0aU70U6dOqWrVqipfvnyO81FZliWbzaaMjIz8VQ0A+URGATAZGQXAZGQUAJORUQBMkOcm+saNG1WxYkVJ0qZNmzxWEADkBxkFwGRkFACTkVEATEZGATBBnpvoXbp0yfHfAGACMgqAycgoACYjowCYjIwCYII8N9Gv9ccff+j999/XDz/8IElq2rSpBg4caP90EAC8iYwCYDIyCoDJyCgAJiOjAHiDT+6LZLd161aFhobq9ddf1x9//KE//vhDr7/+uurWrautW7e6u0YAcAkZBcBkZBQAk5FRAExGRgHwlnzdiT5ixAg9+uijmjt3rnx9fSVJGRkZGj58uEaMGKF9+/a5tUgAcAUZBcBkZBQAk5FRAExGRgHwlnzdiX748GGNHz/eHliS5Ovrq8jISB0+fNhtxQFAfpBRAExGRgEwGRkFwGRkFABvyVcTvU2bNva5p672ww8/qGXLlgUuCgAKgowCYDIyCoDJyCgAJiOjAHhLnqdz+f777+3/Hj16tMaMGaPDhw/rlltukSR9/fXXmjNnjqZNm+b+KgEgF2QUAJORUQBMVlwzKnTCKm+XYHd0Wk9vlwAYq7hmFACz2CzLsvKyoI+Pj2w2m3Jb3GazKSMjwy3FeUJycrKCgoKUlJSkwMDAXJfnFyugcLh6bV6LjPI+MgpFGRl1BRkFmImMuoKMAsxERl1R0PMAwDPyem3m+U70I0eOuKUwAPAEMgqAycgoACYjowCYjIwCYII8N9Hr1KnjyToAoEDIKAAmI6MAmIyMAmAyMgqACfLcRM/JgQMHdPz4caWlpTmM33fffQUqCgDcgYwCYDIyCoDJyCgAJiOjABS2fDXRf/nlFz3wwAPat2+fw7xUNptNkoyegwpA0UdGATAZGQXAZGQUAJORUQC8xSc/K40ZM0Z169ZVQkKCAgIC9L///U9bt25Vu3bttHnzZjeXCACuIaMAmIyMAmAyMgqAycgoAN6SrzvR4+LitHHjRlWuXFk+Pj7y8fFRp06dFBMTo9GjR+u7775zd50AkGdkFACTkVEATEZGATAZGQXAW/J1J3pGRobKlSsnSapcubJ+++03SVce9vDjjz+6rzoAyAcyCoDJyCgAJiOjAJiMjALgLfm6E71Zs2bau3ev6tatqw4dOujll19WqVKl9M4776hevXrurhEAXEJGATAZGQXAZGQUAJORUQC8JV9N9Oeee04pKSmSpBdeeEH33HOPOnfurEqVKmnZsmVuLRAAXEVGATAZGQXAZGQUAJORUQC8JV9N9PDwcPu/GzRooIMHD+rs2bOqUKGC/YnIAOAtZBQAk5FRAExGRgEwGRkFwFvy1US/2okTJyRJtWrVKnAxAOBuZBQAk5FRAExGRgEwGRkFoDDl68Gi6enpev755xUUFKTQ0FCFhoYqKChIzz33nC5fvuzuGgHAJWQUAJORUQBMRkYBMBkZBcBb8nUn+qhRo/Tpp5/q5ZdfVseOHSVJcXFxmjx5sn7//XfNnTvXrUUCgCvIKAAmI6MAmIyMAmAyMgqAt+Srib5kyRItXbpUd999t32sRYsWqlWrlvr27UtoAfAqMgqAycgoACYjowCYjIwC4C35ms7Fz89PoaGh2cbr1q2rUqVKuby9OXPmKDQ0VP7+/urQoYN27NiRp/WWLl0qm82mXr16ubxPAEUXGQXAZGQUAJORUQBMRkYB8JZ8NdFHjhypKVOmKDU11T6Wmpqql156SSNHjnRpW8uWLVNkZKSioqK0e/dutWzZUuHh4UpISLjuekePHtVTTz2lzp075+cQABRhZBQAk5FRAExGRgEwGRkFwFvyPJ3Lgw8+6PB6/fr1qlmzplq2bClJ2rt3r9LS0nTHHXe4VMCsWbM0ZMgQDRw4UJL01ltvadWqVfrggw80YcKEHNfJyMjQ448/rujoaG3btk3nzp1zaZ8Aih4yCoDJyCgAJiOjAJiMjAJggjw30YOCghxeP/TQQw6va9Wq5fLO09LStGvXLk2cONE+5uPjo7CwMMXFxTld74UXXlDVqlU1aNAgbdu27br7SE1NdfiEMjk52eU6AZiPjAJgMjIKgMnIKAAmI6MAmCDPTfR58+a5fednzpxRRkaGgoODHcaDg4N18ODBHNf58ssv9f7772vPnj152kdMTIyio6MLWioAw5FRAExGRgEwGRkFwGRkFAAT5GtO9CyJiYn68ssv9eWXXyoxMdFdNTl1/vx59evXT++++64qV66cp3UmTpyopKQk+9eJEyc8XCUAU5BRAExGRgEwGRkFwGRkFIDCluc70a+WkpKiUaNGaeHChcrMzJQk+fr6qn///nrjjTcUEBCQp+1UrlxZvr6+io+PdxiPj49XSEhItuV//vlnHT16VPfee699LGv/JUqU0I8//qj69es7rOPn5yc/Pz+Xjg/AjY2MAmAyMgqAycgoACYjowB4S77uRI+MjNSWLVv073//W+fOndO5c+e0YsUKbdmyRePHj8/zdkqVKqW2bdtqw4YN9rHMzExt2LBBHTt2zLZ848aNtW/fPu3Zs8f+dd9996lbt27as2dPvubBAlD0kFEATEZGATAZGQXAZGQUAG/J153on3zyiZYvX66uXbvax3r06KHSpUvrkUce0dy5c/O8rcjISEVERKhdu3Zq3769YmNjlZKSYn86cv/+/VWjRg3FxMTI399fzZo1c1i/fPnykpRtHEDxRUYBMBkZBcBkZBQAk5FRALwlX030ixcvZnv4giRVrVpVFy9edGlbjz76qBITEzVp0iSdPn1arVq10po1a+zbP378uHx8CjR1O4BihowCYDIyCoDJyCgAJiOjAHiLzbIsy9WV7rjjDlWqVEkLFy6Uv7+/JOnPP/9URESEzp49q/Xr17u9UHdJTk5WUFCQkpKSFBgYmOvyoRNWFUJVeXN0Wk9vlwB4jKvX5vWQUd5BRqEoI6OuIKMAM5FRV5BRgJnIqCvceR4AuE9er8183YkeGxur7t27q2bNmmrZsqUkae/evfL399fatWvzVzEAuAkZBcBkZBQAk5FRAExGRgHwlnw10Zs3b65Dhw5p8eLFOnjwoCSpb9++evzxx1W6dGm3FggAriKjAJiMjAJgMjIKgMnIKADe4nIT/fLly2rcuLH+85//aMiQIZ6oCQDyjYwCYDIyCoDJyCgAJiOjAHiTy09IKFmypC5duuSJWgCgwMgoACYjowCYjIwCYDIyCoA35esxwyNGjND06dOVnp7u7noAoMDIKAAmI6MAmIyMAmAyMgqAt+RrTvRvv/1WGzZs0H//+181b95cZcqUcfj+p59+6pbiACA/yCgAJiOjAJiMjAJgMjIKgLfkq4levnx5PfTQQ+6uBQDcgowCYDIyCoDJyCgAJiOjAHiLS030zMxMzZgxQz/99JPS0tJ0++23a/LkyTwBGYARyCgAJiOjAJiMjAJgMjIKgLe51ER/6aWXNHnyZIWFhal06dJ6/fXXlZiYqA8++MBT9QFAnpFRAExGRgEwGRllttAJq7xdgt3RaT29XQKKITIKgLe59GDRhQsX6s0339TatWv1+eef69///rcWL16szMxMT9UHAHlGRgEwGRkFwGRkFACTkVEAvM2lJvrx48fVo0cP++uwsDDZbDb99ttvbi8MAFxFRgEwGRkFwGRkFACTkVEAvM2lJnp6err8/f0dxkqWLKnLly+7tSgAyA8yCoDJyCgAJiOjAJiMjALgbS7NiW5ZlgYMGCA/Pz/72KVLl/Tkk0+qTJky9rFPP/3UfRUCQB6RUQBMRkYBMBkZBcBkZBQAb3OpiR4REZFt7IknnnBbMQBQEGQUAJORUQBMRkYBMBkZBcDbXGqiz5s3z1N1AECBkVEATEZGATAZGQXAZGQUAG9zqYkOAAAAAAAAwLNCJ6zydgl2R6f19HYJgNe59GBRAAAAAAAAAACKE+5EBwAAQLHH3V4AAAAAnOFOdAAAAAAAAAAAnKCJDgAAAAAAAACAE0znAgAAAAAAACBfmBYPxQF3ogMAAAAAAAAA4ARNdAAAAAAAAAAAnDCiiT5nzhyFhobK399fHTp00I4dO5wu++6776pz586qUKGCKlSooLCwsOsuDwAFRUYBMBkZBcBkZBQAk5FRAPLK6030ZcuWKTIyUlFRUdq9e7datmyp8PBwJSQk5Lj85s2b1bdvX23atElxcXGqVauW7rrrLp08ebKQKwdQHJBRAExGRgEwGRkFwGRkFABXeL2JPmvWLA0ZMkQDBw5U06ZN9dZbbykgIEAffPBBjssvXrxYw4cPV6tWrdS4cWO99957yszM1IYNGwq5cgDFARkFwGRkFACTkVEATEZGAXCFV5voaWlp2rVrl8LCwuxjPj4+CgsLU1xcXJ62cfHiRV2+fFkVK1bM8fupqalKTk52+AKAvCCjAJiMjAJgMjIKgMnIKACuKuHNnZ85c0YZGRkKDg52GA8ODtbBgwfztI1nnnlG1atXdwi+q8XExCg6OrrAtQIofsgoACYjowCYjIwCYDIyqngLnbDK2yXYHZ3W09slII+8Pp1LQUybNk1Lly7VZ599Jn9//xyXmThxopKSkuxfJ06cKOQqARRXZBQAk5FRAExGRgEwGRkFFD9evRO9cuXK8vX1VXx8vMN4fHy8QkJCrrvuzJkzNW3aNK1fv14tWrRwupyfn5/8/PzcUi+A4oWMAmAyMgqAycgoACYjowC4yqt3opcqVUpt27Z1eAhD1kMZOnbs6HS9l19+WVOmTNGaNWvUrl27wigVQDFERgEwGRkFwGRkFACTkVEAXOXVO9ElKTIyUhEREWrXrp3at2+v2NhYpaSkaODAgZKk/v37q0aNGoqJiZEkTZ8+XZMmTdKSJUsUGhqq06dPS5LKli2rsmXLeu04ABRNZBQAk5FRAExGRgEwGRkFwBVeb6I/+uijSkxM1KRJk3T69Gm1atVKa9assT/c4fjx4/Lx+f8b5ufOnau0tDT17t3bYTtRUVGaPHlyYZYOoBggowCYjIwCYDIyCoDJyCgArvB6E12SRo4cqZEjR+b4vc2bNzu8Pnr0qOcLAoCrkFEATEZGATAZGQXAZGQUgLwyookOAAAAAAAAAHAUOmGVt0uwOzqtp7dL8Bqa6ACAQsH/8QMAAAAAgBuRT+6LAAAAAAAAAABQPNFEBwAAAAAAAADACZroAAAAAAAAAAA4QRMdAAAAAAAAAAAnaKIDAAAAAAAAAOBECW8XAAAAAAAAAAC48YVOWOXtEuyOTuvptm3RRAcAAAAAAG5TVBsoAIDii+lcAAAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMCJEt4uAAAAAAAAwFtCJ6zydgl2R6f19HYJAIAccCc6AAAAAAAAAABOcCc6AAAAcIPhrkkAAACg8BhxJ/qcOXMUGhoqf39/dejQQTt27Lju8h9//LEaN24sf39/NW/eXKtXry6kSgEUR2QUAJORUQBMRkYBMBkZBSCvvN5EX7ZsmSIjIxUVFaXdu3erZcuWCg8PV0JCQo7Lb9++XX379tWgQYP03XffqVevXurVq5f2799fyJUDKA7IKAAmI6MAmIyMAmAyMgqAK7zeRJ81a5aGDBmigQMHqmnTpnrrrbcUEBCgDz74IMflX3vtNXXv3l1PP/20mjRpoilTpqhNmzaaPXt2IVcOoDggowCYjIwCYDIyCoDJyCgArvDqnOhpaWnatWuXJk6caB/z8fFRWFiY4uLiclwnLi5OkZGRDmPh4eH6/PPPPVkqgGKIjAJgMjIKgMnIKMBzeC5GwZFRAFzl1Sb6mTNnlJGRoeDgYIfx4OBgHTx4MMd1Tp8+nePyp0+fznH51NRUpaam2l8nJSVJkpKTk/NUY2bqxTwtVxhyq7lZ1NpCqiR3+6PDvV0CbjBZP9+WZXm5kv9HRrkmt5pvpFolMhWOyKgryKjCkZfze6PVS6Z6Fhl1BRlVOIpiRlFv/uWlXjLqCjKqcBTFa4h688+dGeXVJnphiImJUXR0dLbxWrVqeaGaggmK9XYFeXcj1QqznD9/XkFBQd4uo9CQUd5xI9Uq3Xj1FmVk1BVklGfdSLVK1GsSMuoKMsqzbqRaJer1NFfqJaOuIKM860aqVaJeT3NnRnm1iV65cmX5+voqPj7eYTw+Pl4hISE5rhMSEuLS8hMnTnT4c5vMzEydPXtWlSpVks1mK+AR5C45OVm1atXSiRMnFBgY6PH9FTecX88p7HNrWZbOnz+v6tWre3xfeUVGoaA4v55DRpFRKDjOr+eQUWQUCo7z6zlkFBmFguP8eo6pGeXVJnqpUqXUtm1bbdiwQb169ZJ0JVQ2bNigkSNH5rhOx44dtWHDBo0dO9Y+tm7dOnXs2DHH5f38/OTn5+cwVr58eXeU75LAwEAuKg/i/HpOYZ5b0+5KIKPgLpxfzyGjyCgUHOfXc8goMgoFx/n1HDKKjELBcX49x7SM8vp0LpGRkYqIiFC7du3Uvn17xcbGKiUlRQMHDpQk9e/fXzVq1FBMTIwkacyYMerSpYteeeUV9ezZU0uXLtXOnTv1zjvvePMwABRRZBQAk5FRAExGRgEwGRkFwBVeb6I/+uijSkxM1KRJk3T69Gm1atVKa9assT+s4fjx4/Lx8bEvf+utt2rJkiV67rnn9Oyzz+qmm27S559/rmbNmnnrEAAUYWQUAJORUQBMRkYBMBkZBcAVNsukxyMXQampqYqJidHEiROz/RkPCo7z6zmc2+KB99mzOL+ew7ktHnifPYvz6zmc2+KB99mzOL+ew7ktHnifPYvz6zmmnlua6AAAAAAAAAAAOOGT+yIAAAAAAAAAABRPNNEBAAAAAAAAAHCCJjoAAAAAAAAAAE7QRPewOXPmKDQ0VP7+/urQoYN27Njh7ZJueDExMbr55ptVrlw5Va1aVb169dKPP/7o7bKKpGnTpslms2ns2LHeLgUeQka5HxlVeMiooo+Mcj8yqvCQUUUfGeV+ZFThIaOKPjLK/ciowmNiRtFE96Bly5YpMjJSUVFR2r17t1q2bKnw8HAlJCR4u7Qb2pYtWzRixAh9/fXXWrdunS5fvqy77rpLKSkp3i6tSPn222/19ttvq0WLFt4uBR5CRnkGGVU4yKiij4zyDDKqcJBRRR8Z5RlkVOEgo4o+MsozyKjCYWxGWfCY9u3bWyNGjLC/zsjIsKpXr27FxMR4saqiJyEhwZJkbdmyxdulFBnnz5+3brrpJmvdunVWly5drDFjxni7JHgAGVU4yCj3I6OKBzKqcJBR7kdGFQ9kVOEgo9yPjCoeyKjCQUa5n8kZxZ3oHpKWlqZdu3YpLCzMPubj46OwsDDFxcV5sbKiJykpSZJUsWJFL1dSdIwYMUI9e/Z0+PlF0UJGFR4yyv3IqKKPjCo8ZJT7kVFFHxlVeMgo9yOjij4yqvCQUe5nckaV8HYBRdWZM2eUkZGh4OBgh/Hg4GAdPHjQS1UVPZmZmRo7dqxuu+02NWvWzNvlFAlLly7V7t279e2333q7FHgQGVU4yCj3I6OKBzKqcJBR7kdGFQ9kVOEgo9yPjCoeyKjCQUa5n+kZRRMdN7QRI0Zo//79+vLLL71dSpFw4sQJjRkzRuvWrZO/v7+3ywFueGSUe5FRgHuRUe5FRgHuRUa5FxkFuBcZ5V43QkbRRPeQypUry9fXV/Hx8Q7j8fHxCgkJ8VJVRcvIkSP1n//8R1u3blXNmjW9XU6RsGvXLiUkJKhNmzb2sYyMDG3dulWzZ89WamqqfH19vVgh3IWM8jwyyv3IqOKDjPI8Msr9yKjig4zyPDLK/cio4oOM8jwyyv1uhIxiTnQPKVWqlNq2basNGzbYxzIzM7VhwwZ17NjRi5Xd+CzL0siRI/XZZ59p48aNqlu3rrdLKjLuuOMO7du3T3v27LF/tWvXTo8//rj27Nnj9cCC+5BRnkNGeQ4ZVXyQUZ5DRnkOGVV8kFGeQ0Z5DhlVfJBRnkNGec6NkFHcie5BkZGRioiIULt27dS+fXvFxsYqJSVFAwcO9HZpN7QRI0ZoyZIlWrFihcqVK6fTp09LkoKCglS6dGkvV3djK1euXLa5vMqUKaNKlSoxx1cRREZ5BhnlOWRU8UJGeQYZ5TlkVPFCRnkGGeU5ZFTxQkZ5BhnlOTdCRtFE96BHH31UiYmJmjRpkk6fPq1WrVppzZo12R7uANfMnTtXktS1a1eH8Xnz5mnAgAGFXxBwgyKjPIOMAtyDjPIMMgpwDzLKM8gowD3IKM8go4o3m2VZlreLAAAAAAAAAADARMyJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDiMcPXpUNptNe/bs8XYpAJANGQXAZGQUAJORUQBMRkYhr2iiw21sNtt1vyZPnuztErPp2rWrxo4d6/A6q14/Pz/VqFFD9957rz799FPvFQnALcgoACYjowCYjIwCYDIyCoWBJjrc5tSpU/av2NhYBQYGOow99dRT3i4xT4YMGaJTp07p559/1ieffKKmTZuqT58+Gjp0qLdLA1AAZBQAk5FRAExGRgEwGRmFwkATHW4TEhJi/woKCpLNZrO/rlq1qmbNmqWaNWvKz89PrVq10po1a5xuKyMjQ3/729/UuHFjHT9+XJK0YsUKtWnTRv7+/qpXr56io6OVnp5uX8dms+m9997TAw88oICAAN10001auXKly8cREBCgkJAQ1axZU7fccoumT5+ut99+W++++67Wr1/v+okBYAQyCoDJyCgAJiOjAJiMjEJhoImOQvHaa6/plVde0cyZM/X9998rPDxc9913nw4dOpRt2dTUVD388MPas2ePtm3bptq1a2vbtm3q37+/xowZowMHDujtt9/W/Pnz9dJLLzmsGx0drUceeUTff/+9evTooccff1xnz54tcP0RERGqUKECf0YDFFFkFACTkVEATEZGATAZGQV3oYmOQjFz5kw988wz6tOnjxo1aqTp06erVatWio2NdVjuwoUL6tmzpxITE7Vp0yZVqVJF0pUwmjBhgiIiIlSvXj3deeedmjJlit5++22H9QcMGKC+ffuqQYMGmjp1qi5cuKAdO3YUuH4fHx81bNhQR48eLfC2AJiHjAJgMjIKgMnIKAAmI6PgLiW8XQCKvuTkZP3222+67bbbHMZvu+027d2712Gsb9++qlmzpjZu3KjSpUvbx/fu3auvvvrK4ZO+jIwMXbp0SRcvXlRAQIAkqUWLFvbvlylTRoGBgUpISHDLcViWJZvN5pZtATAHGQXAZGQUAJORUQBMRkbBnWiiwyg9evTQhx9+qLi4ON1+++328QsXLig6OloPPvhgtnX8/f3t/y5ZsqTD92w2mzIzMwtcV0ZGhg4dOqSbb765wNsCcOMiowCYjIwCYDIyCoDJyCjkhiY6PC4wMFDVq1fXV199pS5dutjHv/rqK7Vv395h2WHDhqlZs2a67777tGrVKvvybdq00Y8//qgGDRoUau1ZFixYoD/++EMPPfSQV/YPwHPIKAAmI6MAmIyMAmAyMgruRBMdheLpp59WVFSU6tevr1atWmnevHnas2ePFi9enG3ZUaNGKSMjQ/fcc4+++OILderUSZMmTdI999yj2rVrq3fv3vLx8dHevXu1f/9+vfjii26t9eLFizp9+rTS09P166+/6rPPPtOrr76qYcOGqVu3bm7dFwAzkFEATEZGATAZGQXAZGQU3IUmOgrF6NGjlZSUpPHjxyshIUFNmzbVypUrddNNN+W4/NixY5WZmakePXpozZo1Cg8P13/+8x+98MILmj59ukqWLKnGjRtr8ODBbq/13Xff1bvvvqtSpUqpUqVKatu2rZYtW6YHHnjA7fsCYAYyCoDJyCgAJiOjAJiMjIK72CzLsrxdBAAAAAAAAAAAJvLxdgEAAAAAAAAAAJiKJjoAAAAAAAAAAE7QRAcAAAAAAAAAwAma6AAAAAAAAAAAOEETHQAAAAAAAAAAJ2iiAwAAAAAAAADgBE10AAAAAAAAAACcoIkOAAAAAAAAAIATNNEBAAAAAAAAAHCCJjoAAAAAAAAAAE7QRAcAAAAAAAAAwAma6AAAAAAAAAAAOPF/HtgUcfNgFiIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def demonstrate_division_effect():\n",
        "    \"\"\"\n",
        "    Show how division by temperature amplifies or dampens differences\n",
        "    \"\"\"\n",
        "    original_logit = 6.0\n",
        "\n",
        "    print(\"Original logit: 6.0\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(\"\\nTEMPERATURE < 1 (Division by fraction = MULTIPLICATION)\")\n",
        "    for temp in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
        "        scaled = original_logit / temp\n",
        "        print(f\"6.0 / {temp} = {scaled:.1f} (multiplied by {1/temp:.1f})\")\n",
        "\n",
        "    print(\"\\nTEMPERATURE > 1 (Division = SHRINKING)\")\n",
        "    for temp in [1.0, 1.5, 2.0, 3.0, 5.0]:\n",
        "        scaled = original_logit / temp\n",
        "        print(f\"6.0 / {temp} = {scaled:.1f} (divided by {temp})\")\n",
        "\n",
        "demonstrate_division_effect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnqOImq0UR9J",
        "outputId": "bc588452-a7f8-41c6-b9d2-bade1fd59a84"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original logit: 6.0\n",
            "==================================================\n",
            "\n",
            "TEMPERATURE < 1 (Division by fraction = MULTIPLICATION)\n",
            "6.0 / 0.1 = 60.0 (multiplied by 10.0)\n",
            "6.0 / 0.3 = 20.0 (multiplied by 3.3)\n",
            "6.0 / 0.5 = 12.0 (multiplied by 2.0)\n",
            "6.0 / 0.7 = 8.6 (multiplied by 1.4)\n",
            "6.0 / 0.9 = 6.7 (multiplied by 1.1)\n",
            "\n",
            "TEMPERATURE > 1 (Division = SHRINKING)\n",
            "6.0 / 1.0 = 6.0 (divided by 1.0)\n",
            "6.0 / 1.5 = 4.0 (divided by 1.5)\n",
            "6.0 / 2.0 = 3.0 (divided by 2.0)\n",
            "6.0 / 3.0 = 2.0 (divided by 3.0)\n",
            "6.0 / 5.0 = 1.2 (divided by 5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment : Implement text_generation, apply greedy with different temperatures\n",
        "\n",
        "# there are like dozen different techniques, to explore\n",
        "# but we finish with another two"
      ],
      "metadata": {
        "id": "cZBnTpbKWdLN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top-k sampling\n",
        "\n",
        "# algo find_k_largest values,filter only those values, softmax to get probs\n",
        "# out of those probs get random one, according to given probabilities\n",
        "\n",
        "def simple_top_k(raw_logits,k = 5):\n",
        "    # step 1 find k_largest values, we also need their indices, since it's effectivly token_ids\n",
        "    top_k_logits,top_k_indices = torch.topk(raw_logits,k)\n",
        "\n",
        "    # step 2 create new_logits and filter\n",
        "    filtered_logits = torch.full_like(raw_logits, float('-inf'))\n",
        "    # Use scatter to put values back\n",
        "    filtered_logits.scatter_(-1, top_k_indices, top_k_logits)\n",
        "\n",
        "    # step 3 sample one according to probs\n",
        "    probs = F.softmax(filtered_logits,dim=-1)\n",
        "    next_token = torch.multinomial(probs, 1)\n",
        "\n",
        "    return next_token\n",
        "\n",
        "_,res = generate(model,tokenizer,prompt,15,simple_top_k)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5d_LRe9YQFX",
        "outputId": "7de7aee5-26c3-4863-f7d6-0258a135ec0d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer architecture is 100% open-source and open to anyone to contribute.\n",
            "The Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top-p(nucleus) sampling\n",
        "\n",
        "# algo:\n",
        "# 1) apply softmax to get probabilities and sort them\n",
        "# 2)keep tokens by adding their probabilities till reaching thershold\n",
        "# 3) sample random token haha, I don't know why but\n",
        "# everything is a random, but it works almost\n",
        "\n",
        "def simple_top_p(raw_logits,p = 0.7):\n",
        "    # step1 get probs and sort them\n",
        "    probs = F.softmax(raw_logits,dim=-1)\n",
        "    sorted_probs,sorted_indices = torch.sort(probs,descending =True) # so highes probs goes first\n",
        "\n",
        "    # step2 cumulative_sum\n",
        "    cumsum_probs = torch.cumsum(sorted_probs,dim=-1)\n",
        "\n",
        "    tokens_to_remove = cumsum_probs > p # this will mask all tokens to remove = True\n",
        "    tokens_to_remove[..., 0] = False  # Keep at least first token # try to comment to see the problem\n",
        "    # \"No matter how aggressive our filtering is, always keep the best token!\"\n",
        "\n",
        "    # Create filtered logits\n",
        "    filtered_logits = raw_logits.clone()\n",
        "\n",
        "    # Use scatter to map removal mask back to original positions\n",
        "    indices_to_remove = tokens_to_remove.scatter(-1, sorted_indices, tokens_to_remove)\n",
        "    filtered_logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "    # Sample\n",
        "    probs = F.softmax(filtered_logits, dim=-1)\n",
        "    next_token = torch.multinomial(probs, 1)\n",
        "\n",
        "    return next_token\n",
        "\n",
        "\n",
        "_,res = generate(model,tokenizer,prompt,15,simple_top_p)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkkfMiWka91D",
        "outputId": "d2ef77c3-7916-42b5-b034-068fa4b410dd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer architecture is 1) designed to provide the best results in the context of specific performance requirements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sorting\n",
        "import torch\n",
        "\n",
        "# Simple example\n",
        "values = torch.tensor([3.0, 1.0, 4.0, 1.5, 2.0])\n",
        "print(\"Original:\", values)\n",
        "\n",
        "# Sort in ascending order (default)\n",
        "sorted_vals, sorted_idx = torch.sort(values)\n",
        "print(\"\\nAscending:\")\n",
        "print(\"Sorted values:\", sorted_vals)  # [1.0, 1.5, 2.0, 3.0, 4.0]\n",
        "print(\"Sorted indices:\", sorted_idx)  # [1, 3, 4, 0, 2]\n",
        "#                                        ↑ means values[1]=1.0 is smallest\n",
        "\n",
        "# Sort in descending order\n",
        "sorted_vals, sorted_idx = torch.sort(values, descending=True)\n",
        "print(\"\\nDescending:\")\n",
        "print(\"Sorted values:\", sorted_vals)  # [4.0, 3.0, 2.0, 1.5, 1.0]\n",
        "print(\"Sorted indices:\", sorted_idx)  # [2, 0, 4, 3, 1]\n",
        "#                                        ↑ means values[2]=4.0 is largest\n",
        "\n",
        "# What do indices mean?\n",
        "print(\"\\nReconstruct original from sorted:\")\n",
        "print(\"values[sorted_idx] =\", values[sorted_idx])\n",
        "print(\"This equals sorted_vals:\", sorted_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtSaXg3ud5JG",
        "outputId": "f70a4eb7-4b6c-4564-9911-62b54821961d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: tensor([3.0000, 1.0000, 4.0000, 1.5000, 2.0000])\n",
            "\n",
            "Ascending:\n",
            "Sorted values: tensor([1.0000, 1.5000, 2.0000, 3.0000, 4.0000])\n",
            "Sorted indices: tensor([1, 3, 4, 0, 2])\n",
            "\n",
            "Descending:\n",
            "Sorted values: tensor([4.0000, 3.0000, 2.0000, 1.5000, 1.0000])\n",
            "Sorted indices: tensor([2, 0, 4, 3, 1])\n",
            "\n",
            "Reconstruct original from sorted:\n",
            "values[sorted_idx] = tensor([4.0000, 3.0000, 2.0000, 1.5000, 1.0000])\n",
            "This equals sorted_vals: tensor([4.0000, 3.0000, 2.0000, 1.5000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cumsum\n",
        "# Cumulative sum - running total\n",
        "probs = torch.tensor([0.4, 0.3, 0.15, 0.1, 0.05])\n",
        "print(\"Original probs:\", probs)\n",
        "\n",
        "cumsum = torch.cumsum(probs, dim=-1)\n",
        "print(\"Cumulative sum:\", cumsum)\n",
        "# [0.4, 0.7, 0.85, 0.95, 1.0]\n",
        "#   ↑    ↑     ↑     ↑    ↑\n",
        "#  0.4  +0.3  +0.15 +0.1 +0.05\n",
        "\n",
        "# Visual breakdown:\n",
        "print(\"\\nStep by step:\")\n",
        "print(f\"Position 0: {probs[0]:.2f} = {probs[0]:.2f}\")\n",
        "print(f\"Position 1: {probs[0]:.2f} + {probs[1]:.2f} = {cumsum[1]:.2f}\")\n",
        "print(f\"Position 2: {probs[0]:.2f} + {probs[1]:.2f} + {probs[2]:.2f} = {cumsum[2]:.2f}\")\n",
        "\n",
        "# Why useful for top-p?\n",
        "p = 0.9\n",
        "print(f\"\\nFor p={p}, we want tokens until cumsum > {p}\")\n",
        "print(\"Mask:\", cumsum > p)  # [False, False, False, True, True]\n",
        "print(\"So we keep first 3 tokens (cumsum = 0.85)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg1xVHx1gHAB",
        "outputId": "707d4baf-b056-4e77-8416-3bba420a18f1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original probs: tensor([0.4000, 0.3000, 0.1500, 0.1000, 0.0500])\n",
            "Cumulative sum: tensor([0.4000, 0.7000, 0.8500, 0.9500, 1.0000])\n",
            "\n",
            "Step by step:\n",
            "Position 0: 0.40 = 0.40\n",
            "Position 1: 0.40 + 0.30 = 0.70\n",
            "Position 2: 0.40 + 0.30 + 0.15 = 0.85\n",
            "\n",
            "For p=0.9, we want tokens until cumsum > 0.9\n",
            "Mask: tensor([False, False, False,  True,  True])\n",
            "So we keep first 3 tokens (cumsum = 0.85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tricky one is scatter\n",
        "# Scatter: puts values at specified positions\n",
        "# Think of it as \"reverse indexing\"\n",
        "\n",
        "# Example 1: Basic scatter\n",
        "target = torch.zeros(5)\n",
        "indices = torch.tensor([2, 0, 4])  # Where to put values\n",
        "values = torch.tensor([10., 20., 30.])  # What to put\n",
        "\n",
        "target.scatter_(0, indices, values)\n",
        "print(\"After scatter:\", target)  # [20., 0., 10., 0., 30.]\n",
        "#                                     ↑        ↑         ↑\n",
        "#                                  idx=0     idx=2     idx=4\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG7oITJOgWgY",
        "outputId": "dda2a2bf-4ab0-4291-e8b3-620e652cc8ca"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After scatter: tensor([20.,  0., 10.,  0., 30.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ok based on these 3 ideas, it seems like they can kill each other\n",
        "# so for example if temp is low, it automatically makes one probability higher so basicaly top_p is useless,\n",
        "# since I will sample from 1"
      ],
      "metadata": {
        "id": "-C9gLA8-goVn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so less is more\n",
        "def the_bottom_line():\n",
        "\n",
        "    print(\"The Paradox:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Low temp → Peaked distribution → Top-p keeps 1 token\")\n",
        "    print(\"High temp → Flat distribution → Top-k becomes limiting factor\")\n",
        "\n",
        "    print(\"\\nThe Solution:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"DON'T use all three at full strength!\")\n",
        "    print(\"\")\n",
        "    print(\"Option 1: temp(0.7-0.9) + top_p(0.9)\")\n",
        "    print(\"Option 2: temp(0.3-0.5) + top_k(20)\")\n",
        "    print(\"Option 3: temp(0.0) + nothing (greedy)\") # here notice the bug I have in my code\n",
        "    # let's address it !\n",
        "\n",
        "    print(\"\\nThe Rule of Thumb:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"If temp < 0.5: Don't bother with top-p\")\n",
        "    print(\"If temp > 1.5: You need constraints (top-k or top-p)\")\n",
        "    print(\"If temp ≈ 1.0: Both top-k and top-p are useful\")\n",
        "\n",
        "the_bottom_line()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNQzTNrLiLe8",
        "outputId": "2f84096e-b530-4853-ed33-d52285fa2cc5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Paradox:\n",
            "----------------------------------------\n",
            "Low temp → Peaked distribution → Top-p keeps 1 token\n",
            "High temp → Flat distribution → Top-k becomes limiting factor\n",
            "\n",
            "The Solution:\n",
            "----------------------------------------\n",
            "DON'T use all three at full strength!\n",
            "\n",
            "Option 1: temp(0.7-0.9) + top_p(0.9)\n",
            "Option 2: temp(0.3-0.5) + top_k(20)\n",
            "Option 3: temp(0.0) + nothing (greedy)\n",
            "\n",
            "The Rule of Thumb:\n",
            "----------------------------------------\n",
            "If temp < 0.5: Don't bother with top-p\n",
            "If temp > 1.5: You need constraints (top-k or top-p)\n",
            "If temp ≈ 1.0: Both top-k and top-p are useful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPy700qQlFGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
